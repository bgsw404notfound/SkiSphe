{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7c00fb3-c9b8-47d0-af07-c19d0686f256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in associates_with_grouped_skills.csv: ['associate_id', 'name', 'role', 'years_of_experience', 'grade', 'project_id', 'certifications_obtained', 'certifications_in_progress', 'available_learning_time', 'learning_time_utilized_previous_year', 'System Design', 'Cloud Architecture', 'Microservices Architecture', 'Performance Optimization', 'Scalability Design', 'CI/CD Pipeline Design', 'Event-Driven Architecture', 'CQRS Pattern', 'Hexagonal Architecture', 'Domain-Driven Design', 'Service Mesh', 'API Gateway Patterns', 'EDA Patterns', 'Saga Pattern', 'Circuit Breaker', 'BFF Pattern', 'Strangler Pattern', 'Anti-Corruption Layer', 'Modular Monolith', 'Quantum Computing Architecture', 'AI System Design', 'Blockchain Architecture', 'Edge Computing Architecture', 'Data Mesh Design', 'Digital Twin Architecture', 'Compliance by Design', 'Sustainability Architecture', 'Chaos Engineering Design', 'Cognitive Architecture', 'Git', 'Agile Methodologies', 'Problem Solving', 'Communication', 'Technical Documentation', 'Debugging', 'Code Review', 'Pair Programming', 'Mentoring', 'Stakeholder Communication', 'Time Management', 'Critical Thinking', 'Continuous Learning', 'Remote Collaboration', 'Digital Literacy', 'Emotional Intelligence', 'Conflict Resolution', 'Adaptability', 'Creativity', 'Data Literacy', 'Visual Thinking', 'Systems Thinking', 'Future Thinking', 'Program Management', 'WebAssembly', 'Cloud Compliance', 'Contract Testing', 'Multi-Cloud Strategy', 'FFI', 'Dart', 'Cloud Carbon Footprint Reduction', 'Stakeholder Mapping', 'Prompt Engineering', 'Vulnerability Assessment', 'UX Metrics', 'UX for Blockchain', 'Database Observability', 'Emotional Design', 'NoSQL', 'REST API', 'Stakeholder Management', 'JNI', 'Architectural Decision Records', 'GitOps', 'Load Testing', 'Playwright', 'Tekton', 'Serverless', 'Threat Intelligence', 'Visual Testing', 'Engineering Culture Development', 'Causal Inference', 'Infrastructure as Code', 'Metaverse Design', 'Innovation Management', 'SQL', 'Computer Vision', 'Python', 'Java', 'JavaScript', 'TypeScript', 'Spring Boot', 'React', 'Angular', 'Microservices', 'Unit Testing', 'Kotlin', 'Swift', 'Flutter', 'GraphQL', 'RxJS', 'Next.js', 'NestJS', 'Jest', 'Deno', 'Rust', 'Web3', 'Blockchain', 'Smart Contracts', 'Three.js', 'Web Components', 'Electron', 'Database Migration', 'Power BI Reporting', 'Multi-Model Databases', 'Wireframing', 'Value Stream Mapping', 'Sustainable Cloud', 'Crisis Management', 'JUnit', 'Model Deployment', 'Database Performance Tuning', 'Explainable AI', 'Digital Transformation', 'Platform Engineering Leadership', 'Test Observability', 'AI Ethics', 'Feature Engineering', 'AI Testing', 'Graph Machine Learning', 'Cloud Security Posture Management', 'Blockchain Security', 'Database Design', 'Cloud IoT Architecture', 'Zero Trust Architecture', 'Service Virtualization', 'Jenkins', 'MLOps', 'Scrum', 'Quantum Machine Learning', 'Selenium', 'Cypress', 'JMeter', 'Security Testing', 'Test Automation', 'BDD', 'Cucumber', 'Postman', 'SoapUI', 'Karate', 'Robot Framework', 'TestNG', 'Allure Reports', 'Gatling', 'BrowserStack', 'Sauce Labs', 'PACT', 'Mutation Testing', 'Accessibility Testing', 'Chaos Testing', 'Performance Engineering', 'Test Data Management', 'Team Management', 'UX Strategy', 'PyTorch', 'Reinforcement Learning', 'UI Design', 'Cloud Blockchain', 'Engineering Metrics', 'Future Trends Analysis', 'Confluence', 'FinOps', 'Columnar Databases', 'Neurodesign', 'Portfolio Management', 'Graph Database Analytics', 'Cloud AR/VR', 'JIRA Administration', 'Sustainability Project Management', 'SBOM Management', 'Agile Transformation', 'Quantum UX', 'Motion Design', 'System Architecture', 'Google Cloud', 'SOC 2', 'AI Infrastructure', 'Technical Leadership', 'Code Reviews', 'Mentorship', 'Agile Coaching', 'Tech Radar Creation', 'Developer Productivity', 'Backlog Refinement', 'Technical Debt Management', 'Incident Management', 'Post-Mortems', 'AI Engineering Leadership', 'Developer Experience', 'InnerSource Leadership', 'Open Source Strategy', 'Technical Evangelism', 'Future Tech Adoption', 'Skills Gap Analysis', 'Technical Career Pathing', 'GDPR Compliance', 'Adobe XD', 'Regulatory Compliance Management', 'Time-Series DBs', 'Software Supply Chain Security', 'Cloud-Native Design', 'Database as Code', 'Terraform', 'Data Pipelines', 'Cloud Cost Optimization', 'MLOps Pipelines', 'Spark', 'Project Planning', 'Risk Management', 'Resource Allocation', 'Budget Forecasting', 'Benefits Realization', 'Change Management', 'Business Case Development', 'AI Project Management', 'Blockchain Project Governance', 'Remote Team Leadership', 'Merger & Acquisition Integration', 'TensorFlow', 'Crossplane', 'AI Security', 'Accessibility Design', 'IoT Security', 'Blue Teaming', 'Cloud Migration', 'User Research', 'Change Data Capture', 'Generative AI', 'Usability Testing', 'Database Federation', 'Augmented Reality Interfaces', 'Identity Management', 'Chaos Engineering', 'Query Optimization', 'Backup & Recovery', 'Data Modeling', 'ETL Processes', 'Vector Databases', 'Database Sharding', 'Database Security', 'Data Warehousing', 'AI Database Optimization', 'Blockchain Databases', 'Database DevOps', 'NewSQL', 'Database Quantum Computing', 'SIEM', 'Prototyping', 'Networking', 'GitHub Actions', 'Data Visualization', 'Linux Administration', 'ArgoCD', 'Cloud Automation', 'User Flows', 'Machine Learning', 'Big Data', 'Statistical Analysis', 'LangChain', 'LLM Fine-Tuning', 'Hugging Face Transformers', 'Federated Learning', 'Time Series Forecasting', 'Anomaly Detection', 'AI Governance', 'Cloud Governance', 'Cross-Cultural UX', 'Design Systems', 'API Security', 'Secure Code Review', 'Cloud Infrastructure', 'Quantum Cloud Computing', 'Red Teaming', 'Kubernetes', 'Edge Computing', 'AI Cloud Architecture', 'Sustainable UX', '5G Security', 'Figma', 'Cloud Metaverse', 'Platform Engineering', 'UX Writing', 'Grafana', 'Azure', 'MITRE ATT&CK', 'Docker', 'AWS', 'Cloud Security', 'Cloud Digital Twins', 'Cloud Robotics', 'Quantum Cryptography', 'Prometheus', 'Firewalls', 'Service Design', 'UX for IoT', 'Observability', 'Internal Developer Platforms', 'Container Security', 'Biometric Security', 'Policy as Code', 'Spinnaker', 'Security Automation', 'Penetration Testing', 'Cryptography', 'Threat Modeling', 'AI UX Design', 'Voice UI Design', 'Inclusive Design', 'GitLab CI/CD', 'skills_recommended_by_manager', 'skills_recommended_by_department', 'skills_selected_for_own', 'L1', 'L2', 'L3', 'L4']\n",
      "Columns in projects_with_grouped_skills.csv: ['project_id', 'project_name', 'Project_status', 'Team Management', 'Project Planning', 'Unit Testing', 'Compliance by Design', 'Neurodesign', 'AI Engineering Leadership', 'SIEM', 'Backlog Refinement', 'Program Management', 'Design Systems', 'GDPR Compliance', 'Prototyping', 'Electron', 'Vector Databases', 'Three.js', 'TensorFlow', 'Portfolio Management', 'UX Strategy', 'Grafana', 'Next.js', 'Crossplane', 'WebAssembly', 'Problem Solving', 'Microservices', 'Database DevOps', 'PyTorch', 'Karate', 'LangChain', 'Business Case Development', 'API Security', 'Cloud Compliance', 'Prometheus', 'Database Migration', 'TestNG', 'Contract Testing', 'Spring Boot', 'Spinnaker', 'Power BI Reporting', 'Angular', 'Multi-Model Databases', 'Database Sharding', 'Reinforcement Learning', 'JMeter', 'Graph Database Analytics', 'Firewalls', 'Cloud AR/VR', 'Incident Management', 'Cognitive Architecture', 'Networking', 'Code Review', 'Technical Debt Management', 'Wireframing', 'Value Stream Mapping', 'Blockchain', 'Quantum Computing Architecture', 'Multi-Cloud Strategy', 'FFI', 'AI Security', 'GitLab CI/CD', 'Biometric Security', 'Microservices Architecture', 'Digital Twin Architecture', 'Sustainable Cloud', 'Accessibility Design', 'Adaptability', 'Cloud Robotics', 'Crisis Management', 'Azure', 'Dart', 'JUnit', 'Swift', 'Cloud Carbon Footprint Reduction', 'JIRA Administration', 'Model Deployment', 'Adobe XD', 'ArgoCD', 'AI UX Design', 'Database Performance Tuning', 'Explainable AI', 'Statistical Analysis', 'IoT Security', 'Test Data Management', 'Code Reviews', 'Post-Mortems', 'Digital Transformation', 'Saga Pattern', 'Sustainability Project Management', 'SBOM Management', 'AI Project Management', 'Regulatory Compliance Management', 'Quantum Cloud Computing', 'TypeScript', 'Platform Engineering Leadership', 'Sustainability Architecture', 'Hexagonal Architecture', 'AI Database Optimization', 'Cryptography', 'Blue Teaming', 'Anomaly Detection', 'GitHub Actions', 'Test Observability', 'Critical Thinking', 'AI Ethics', 'Feature Engineering', 'Rust', 'Cloud Automation', 'Conflict Resolution', 'Cloud Migration', '5G Security', 'Communication', 'Blockchain Databases', 'Mentorship', 'Kotlin', 'Stakeholder Mapping', 'Future Thinking', 'Prompt Engineering', 'Big Data', 'User Research', 'AI Testing', 'Vulnerability Assessment', 'Agile Transformation', 'Change Data Capture', 'Data Visualization', 'AWS', 'Cucumber', 'Red Teaming', 'UX Metrics', 'UX for IoT', 'Systems Thinking', 'Penetration Testing', 'AI Governance', 'Cloud Architecture', 'Continuous Learning', 'Graph Machine Learning', 'Cloud Security Posture Management', 'Robot Framework', 'Generative AI', 'Blockchain Security', 'Git', 'InnerSource Leadership', 'Usability Testing', 'Pair Programming', 'UI Design', 'Risk Management', 'Kubernetes', 'Database Design', 'Test Automation', 'Cloud Blockchain', 'Inclusive Design', 'Digital Literacy', 'UX for Blockchain', 'Database Observability', 'RxJS', 'Blockchain Project Governance', 'Remote Collaboration', 'Gatling', 'Emotional Design', 'Agile Methodologies', 'Figma', 'Backup & Recovery', 'Database Federation', 'Modular Monolith', 'Java', 'NoSQL', 'Database Quantum Computing', 'Quantum UX', 'Scalability Design', 'Cloud Security', 'Cloud IoT Architecture', 'Benefits Realization', 'Allure Reports', 'Voice UI Design', 'Budget Forecasting', 'Cloud Digital Twins', 'Machine Learning', 'REST API', 'Threat Modeling', 'Accessibility Testing', 'Query Optimization', 'Performance Optimization', 'Skills Gap Analysis', 'Cloud Metaverse', 'Container Security', 'Performance Engineering', 'Time-Series DBs', 'Selenium', 'Stakeholder Communication', 'Software Supply Chain Security', 'Engineering Metrics', 'NewSQL', 'Stakeholder Management', 'Cloud Governance', 'JNI', 'Emotional Intelligence', 'Domain-Driven Design', 'MITRE ATT&CK', 'Motion Design', 'Flutter', 'BDD', 'Sauce Labs', 'CQRS Pattern', 'Architectural Decision Records', 'JavaScript', 'LLM Fine-Tuning', 'Chaos Testing', 'Future Trends Analysis', 'Developer Experience', 'Web Components', 'GitOps', 'Security Automation', 'Cloud-Native Design', 'Load Testing', 'Jest', 'System Architecture', 'Secure Code Review', 'React', 'AI System Design', 'PACT', 'Playwright', 'Augmented Reality Interfaces', 'Strangler Pattern', 'System Design', 'ETL Processes', 'Identity Management', 'Google Cloud', 'NestJS', 'Visual Thinking', 'BrowserStack', 'Zero Trust Architecture', 'Edge Computing', 'Change Management', 'Technical Documentation', 'Tekton', 'Policy as Code', 'Developer Productivity', 'Service Virtualization', 'Serverless', 'Database Security', 'Merger & Acquisition Integration', 'SOC 2', 'BFF Pattern', 'Platform Engineering', 'User Flows', 'Service Mesh', 'Data Modeling', 'Federated Learning', 'Postman', 'Jenkins', 'Tech Radar Creation', 'Mentoring', 'Technical Evangelism', 'SoapUI', 'Chaos Engineering Design', 'Threat Intelligence', 'Agile Coaching', 'Mutation Testing', 'Remote Team Leadership', 'MLOps', 'Debugging', 'Security Testing', 'Web3', 'Confluence', 'Database as Code', 'Time Series Forecasting', 'FinOps', 'Quantum Cryptography', 'Cross-Cultural UX', 'Smart Contracts', 'Technical Leadership', 'UX Writing', 'Circuit Breaker', 'Cypress', 'Visual Testing', 'Python', 'Engineering Culture Development', 'Causal Inference', 'Columnar Databases', 'Scrum', 'AI Cloud Architecture', 'Event-Driven Architecture', 'Deno', 'Data Literacy', 'Sustainable UX', 'EDA Patterns', 'Cloud Infrastructure', 'Data Warehousing', 'Quantum Machine Learning', 'Linux Administration', 'Terraform', 'Time Management', 'Data Pipelines', 'Cloud Cost Optimization', 'Infrastructure as Code', 'Blockchain Architecture', 'AI Infrastructure', 'Edge Computing Architecture', 'Observability', 'Open Source Strategy', 'Creativity', 'API Gateway Patterns', 'Metaverse Design', 'Innovation Management', 'Anti-Corruption Layer', 'Technical Career Pathing', 'Hugging Face Transformers', 'MLOps Pipelines', 'Service Design', 'Future Tech Adoption', 'Docker', 'Data Mesh Design', 'Internal Developer Platforms', 'Resource Allocation', 'CI/CD Pipeline Design', 'SQL', 'Computer Vision', 'Spark', 'GraphQL', 'Chaos Engineering', 'L1', 'L2', 'L3', 'L4']\n",
      "Columns in learning_preferences.csv: ['preference_id', 'associate_id', 'preferred_format', 'weekly_hours', 'preferred_domain']\n",
      "Columns in ml_data: ['associate_id', 'skill', 'current_level', 'desired_level', 'years_of_experience']\n",
      "Model accuracy: 0.72\n",
      "NLP pipeline loaded\n",
      "Course embeddings computed\n",
      "Learning paths assigned\n",
      "Clusters assigned\n",
      "✅ AI-enhanced learning pathways saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from transformers import pipeline, logging\n",
    "from sklearn.cluster import KMeans\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Suppress transformer logs and disable tokenizers parallelism\n",
    "logging.set_verbosity_error()\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Load datasets\n",
    "associates = pd.read_csv(\"associates_with_grouped_skills.csv\")\n",
    "projects = pd.read_csv(\"projects_with_grouped_skills.csv\")\n",
    "learning_content = pd.read_csv(\"learning_content.csv\")\n",
    "preferences = pd.read_csv(\"learning_preferences.csv\")\n",
    "\n",
    "# Print columns for debugging\n",
    "print(\"Columns in associates_with_grouped_skills.csv:\", associates.columns.tolist())\n",
    "print(\"Columns in projects_with_grouped_skills.csv:\", projects.columns.tolist())\n",
    "print(\"Columns in learning_preferences.csv:\", preferences.columns.tolist())\n",
    "\n",
    "# Define skill levels\n",
    "skill_levels = {\"L1\": 1, \"L2\": 2, \"L3\": 3, \"L4\": 4}\n",
    "inverse_skill_levels = {1: \"L1\", 2: \"L2\", 3: \"L3\", 4: \"L4\"}\n",
    "\n",
    "# Identify skill columns in associates\n",
    "metadata_columns_assoc = ['associate_id', 'name', 'role', 'years_of_experience', 'grade', 'project_id', \n",
    "                         'certifications_obtained', 'certifications_in_progress', 'available_learning_time', \n",
    "                         'learning_time_utilized_previous_year', 'skills_recommended_by_manager', \n",
    "                         'skills_recommended_by_department', 'skills_selected_for_own']\n",
    "skill_columns_assoc = [col for col in associates.columns if col not in metadata_columns_assoc]\n",
    "\n",
    "# Identify skill columns in projects\n",
    "metadata_columns_proj = ['project_id', 'project_name', 'Project_status']\n",
    "skill_columns_proj = [col for col in projects.columns if col not in metadata_columns_proj]\n",
    "\n",
    "# Prepare ML data for skill gap prediction\n",
    "def prepare_ml_data():\n",
    "    data = []\n",
    "    for _, row in associates.iterrows():\n",
    "        for skill in skill_columns_assoc:\n",
    "            current_level = row[skill]\n",
    "            if pd.notna(current_level):\n",
    "                current_level_int = skill_levels.get(current_level, 1)\n",
    "                desired_level = min(current_level_int + np.random.randint(1, 3), 4)\n",
    "                data.append({\n",
    "                    \"associate_id\": row[\"associate_id\"],\n",
    "                    \"skill\": skill,\n",
    "                    \"current_level\": current_level_int,\n",
    "                    \"desired_level\": desired_level,\n",
    "                    \"years_of_experience\": row[\"years_of_experience\"]\n",
    "                })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "ml_data = prepare_ml_data()\n",
    "print(\"Columns in ml_data:\", ml_data.columns.tolist())\n",
    "\n",
    "# Train RandomForest model\n",
    "if not ml_data.empty:\n",
    "    X = ml_data[[\"current_level\", \"years_of_experience\"]]\n",
    "    y = ml_data[\"desired_level\"]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"Model accuracy: {model.score(X_test, y_test):.2f}\")\n",
    "else:\n",
    "    print(\"No data to train ML model; proceeding with rule-based gaps\")\n",
    "\n",
    "# Predict skill gaps\n",
    "def calculate_skill_gap_ml(row, skill):\n",
    "    current_level = row[skill] if skill in row and pd.notna(row[skill]) else None\n",
    "    if current_level is None:\n",
    "        return None\n",
    "    current_level_int = skill_levels.get(current_level, 1)\n",
    "    features = pd.DataFrame([[current_level_int, row[\"years_of_experience\"]]], \n",
    "                            columns=[\"current_level\", \"years_of_experience\"])\n",
    "    desired_level_int = model.predict(features)[0] if 'model' in globals() else current_level_int + 1\n",
    "    if desired_level_int > current_level_int:\n",
    "        return {\"skill\": skill, \"current_level\": current_level, \"desired_level\": inverse_skill_levels[desired_level_int]}\n",
    "    return None\n",
    "\n",
    "# NLP for course recommendation\n",
    "nlp = pipeline(\"feature-extraction\", model=\"distilbert-base-uncased\", framework=\"pt\")\n",
    "print(\"NLP pipeline loaded\")\n",
    "\n",
    "def get_embedding(text):\n",
    "    with torch.no_grad():\n",
    "        embedding = nlp(text)[0]\n",
    "    return np.mean(embedding, axis=0)\n",
    "\n",
    "# Use 'Title' column for embeddings\n",
    "learning_content[\"embedding\"] = learning_content[\"Title\"].apply(get_embedding)\n",
    "print(\"Course embeddings computed\")\n",
    "\n",
    "def recommend_course_nlp(skill, desired_level, delivery_mode=None):\n",
    "    skill_embedding = get_embedding(skill)\n",
    "    similarities = learning_content[\"embedding\"].apply(\n",
    "        lambda x: np.dot(x, skill_embedding) / (np.linalg.norm(x) * np.linalg.norm(skill_embedding))\n",
    "    )\n",
    "    candidates = learning_content.copy()\n",
    "    candidates[\"similarity\"] = similarities\n",
    "    candidates = candidates[candidates[\"Level\"] == desired_level]\n",
    "    if delivery_mode:\n",
    "        candidates = candidates[candidates[\"Format\"] == delivery_mode]\n",
    "    if not candidates.empty:\n",
    "        best_match = candidates.loc[candidates[\"similarity\"].idxmax()]\n",
    "        return best_match[\"Title\"]\n",
    "    return \"No suitable course found\"\n",
    "\n",
    "# Identify skill gaps and create learning paths\n",
    "def create_learning_path(row):\n",
    "    associate_id = row[\"associate_id\"]\n",
    "    learning_path = []\n",
    "\n",
    "    # Get associate's skills\n",
    "    assoc_skills = {skill: row[skill] for skill in skill_columns_assoc}\n",
    "\n",
    "    # Get preferred format from learning_preferences.csv\n",
    "    assoc_prefs = preferences[preferences[\"associate_id\"] == associate_id]\n",
    "    delivery_mode = assoc_prefs[\"preferred_format\"].iloc[0] if not assoc_prefs.empty else None\n",
    "\n",
    "    # 1. Project-based skill gaps\n",
    "    assoc_project_id = row[\"project_id\"]\n",
    "    assoc_projects = projects[projects[\"project_id\"] == assoc_project_id]\n",
    "    \n",
    "    for _, proj in assoc_projects.iterrows():\n",
    "        for req_skill in skill_columns_proj:\n",
    "            req_level = proj[req_skill]\n",
    "            if pd.notna(req_level):\n",
    "                req_level_int = skill_levels.get(req_level, 1)\n",
    "                current_level = assoc_skills.get(req_skill, None)\n",
    "                current_level_int = skill_levels.get(current_level, 1) if pd.notna(current_level) else 1\n",
    "                \n",
    "                if current_level_int < req_level_int:\n",
    "                    gap = {\"skill\": req_skill, \"current_level\": current_level if pd.notna(current_level) else \"Not Known\", \n",
    "                           \"desired_level\": req_level}\n",
    "                    course = recommend_course_nlp(req_skill, req_level, delivery_mode)\n",
    "                    learning_path.append({\"type\": \"project\", \"skill\": req_skill, \"course\": course})\n",
    "\n",
    "    # 2. Manager and department needs (from associates_with_grouped_skills.csv)\n",
    "    # Parse manager-recommended skills\n",
    "    manager_skills = row[\"skills_recommended_by_manager\"]\n",
    "    if pd.notna(manager_skills):\n",
    "        for skill in manager_skills.split(\",\"):\n",
    "            skill = skill.strip()\n",
    "            current_level = assoc_skills.get(skill, None)\n",
    "            current_level_int = skill_levels.get(current_level, 1) if pd.notna(current_level) else 1\n",
    "            desired_level_int = current_level_int + 1 if current_level_int < 4 else 4  # Aim for the next level\n",
    "            desired_level = inverse_skill_levels[desired_level_int]\n",
    "            \n",
    "            if current_level_int < desired_level_int:\n",
    "                course = recommend_course_nlp(skill, desired_level, delivery_mode)\n",
    "                learning_path.append({\"type\": \"manager\", \"skill\": skill, \"course\": course})\n",
    "\n",
    "    # Parse department-recommended skills\n",
    "    dept_skills = row[\"skills_recommended_by_department\"]\n",
    "    if pd.notna(dept_skills):\n",
    "        for skill in dept_skills.split(\",\"):\n",
    "            skill = skill.strip()\n",
    "            current_level = assoc_skills.get(skill, None)\n",
    "            current_level_int = skill_levels.get(current_level, 1) if pd.notna(current_level) else 1\n",
    "            desired_level_int = current_level_int + 1 if current_level_int < 4 else 4\n",
    "            desired_level = inverse_skill_levels[desired_level_int]\n",
    "            \n",
    "            if current_level_int < desired_level_int:\n",
    "                course = recommend_course_nlp(skill, desired_level, delivery_mode)\n",
    "                learning_path.append({\"type\": \"department\", \"skill\": skill, \"course\": course})\n",
    "\n",
    "    # 3. Skill progression\n",
    "    for skill in assoc_skills:\n",
    "        if pd.notna(assoc_skills[skill]):\n",
    "            gap = calculate_skill_gap_ml(row, skill)\n",
    "            if gap:\n",
    "                course = recommend_course_nlp(gap[\"skill\"], gap[\"desired_level\"], delivery_mode)\n",
    "                learning_path.append({\"type\": \"progression\", \"skill\": gap[\"skill\"], \"course\": course})\n",
    "\n",
    "    return learning_path\n",
    "\n",
    "associates[\"learning_path\"] = associates.apply(create_learning_path, axis=1)\n",
    "print(\"Learning paths assigned\")\n",
    "\n",
    "# Clustering for personalization\n",
    "skill_matrix = associates[skill_columns_assoc].map(lambda x: skill_levels.get(x, 0))\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "associates[\"cluster\"] = kmeans.fit_predict(skill_matrix)\n",
    "print(\"Clusters assigned\")\n",
    "\n",
    "# Save results\n",
    "filtered_associates = associates[[\"associate_id\", \"role\", \"learning_path\", \"cluster\"]]\n",
    "filtered_associates.to_csv(\"learning_pathways.csv\", index=False)\n",
    "\n",
    "print(\"✅ AI-enhanced learning pathways saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be043731-1265-41f7-9f33-cece99b1d4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in learning_preferences.csv: ['preference_id', 'associate_id', 'preferred_format', 'weekly_hours', 'preferred_domain']\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in learning_preferences.csv:\", preferences.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb03b8a-3a1c-414f-827c-30c074b97ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
