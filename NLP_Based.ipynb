{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Sf9r0dxiG-EXdmfbzHcLc-n97LoFu9ZR",
      "authorship_tag": "ABX9TyPpkX7wS6K6wYIRTZvFRQ/s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bgsw404notfound/SkiSphe/blob/main/NLP_Based.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8BIwOpkSP5m",
        "outputId": "63ce2143-7eeb-471a-cc79-9176114a0fa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning:\n",
            "\n",
            "\n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4fbf8f532d3d42659c3a5c31f6acfd85"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0368c4a6b9a74f75bc00b07b6b0c540d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "697b96458c4e415086c552e8d460daa7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70b8bdffc7a745c2afc95194e718c904"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86d0d6325ba7481cb3065605def764ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP pipeline loaded\n",
            "Precomputing course embeddings...\n",
            "Processing learning paths in parallel...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import pipeline, logging\n",
        "import torch\n",
        "import os\n",
        "from multiprocessing import Pool\n",
        "\n",
        "# Suppress transformer logs and disable tokenizers parallelism\n",
        "logging.set_verbosity_error()\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "# Load datasets\n",
        "associates = pd.read_csv(\"/content/drive/MyDrive/SkillSphe/associates_with_grouped_skills.csv\")\n",
        "projects = pd.read_csv(\"/content/drive/MyDrive/SkillSphe/projects_with_grouped_skills.csv\")\n",
        "learning_content = pd.read_csv(\"/content/drive/MyDrive/SkillSphe/learning_content.csv\")\n",
        "preferences = pd.read_csv(\"/content/drive/MyDrive/SkillSphe/learning_preferences.csv\")\n",
        "\n",
        "# Convert project_id to string\n",
        "associates[\"project_id\"] = associates[\"project_id\"].astype(str)\n",
        "projects[\"project_id\"] = projects[\"project_id\"].astype(str)\n",
        "\n",
        "# Define skill levels\n",
        "skill_levels = {\"L1\": 1, \"L2\": 2, \"L3\": 3, \"L4\": 4}\n",
        "inverse_skill_levels = {1: \"L1\", 2: \"L2\", 3: \"L3\", 4: \"L4\"}\n",
        "\n",
        "# Identify skill columns\n",
        "metadata_columns_assoc = ['associate_id', 'name', 'role', 'years_of_experience', 'grade', 'project_id',\n",
        "                         'certifications_obtained', 'certifications_in_progress', 'available_learning_time',\n",
        "                         'learning_time_utilized_previous_year', 'skills_recommended_by_manager',\n",
        "                         'skills_recommended_by_department', 'skills_selected_for_own', 'L1', 'L2', 'L3', 'L4']\n",
        "skill_columns_assoc = [col for col in associates.columns if col not in metadata_columns_assoc]\n",
        "\n",
        "metadata_columns_proj = ['project_id', 'project_name', 'Project_status']\n",
        "skill_columns_proj = [col for col in projects.columns if col not in metadata_columns_proj]\n",
        "\n",
        "# NLP setup\n",
        "nlp = pipeline(\"feature-extraction\", model=\"distilbert-base-uncased\", framework=\"pt\")\n",
        "print(\"NLP pipeline loaded\")\n",
        "\n",
        "def get_embedding(text):\n",
        "    with torch.no_grad():\n",
        "        embedding = nlp(text)[0]\n",
        "    return np.mean(embedding, axis=0)\n",
        "\n",
        "# Precompute course embeddings\n",
        "print(\"Precomputing course embeddings...\")\n",
        "learning_content[\"embedding\"] = learning_content[\"Title\"].apply(get_embedding)\n",
        "\n",
        "# Batch recommendation function\n",
        "def batch_recommend_courses(skills_levels, delivery_mode=None):\n",
        "    skill_embeddings = {skill: get_embedding(skill) for skill, _ in skills_levels if skill}\n",
        "    results = {}\n",
        "    for skill, desired_level in skills_levels:\n",
        "        if not skill:\n",
        "            results[(skill, desired_level)] = \"No suitable course found\"\n",
        "            continue\n",
        "        similarities = learning_content[\"embedding\"].apply(\n",
        "            lambda x: np.dot(x, skill_embeddings[skill]) / (np.linalg.norm(x) * np.linalg.norm(skill_embeddings[skill]))\n",
        "        )\n",
        "        candidates = learning_content[learning_content[\"Level\"] == desired_level].copy()\n",
        "        if delivery_mode:\n",
        "            candidates = candidates[candidates[\"Format\"] == delivery_mode]\n",
        "        candidates[\"similarity\"] = similarities[candidates.index]\n",
        "        skill_lower = skill.lower()\n",
        "        candidates[\"keyword_match\"] = candidates[\"Title\"].str.lower().str.contains(skill_lower).astype(int)\n",
        "        candidates = candidates.sort_values(by=[\"keyword_match\", \"similarity\"], ascending=[False, False])\n",
        "        results[(skill, desired_level)] = candidates.iloc[0][\"Title\"] if not candidates.empty else \"No suitable course found\"\n",
        "    return results\n",
        "\n",
        "# Function to convert 'L<number>' to integer\n",
        "def level_to_int(value):\n",
        "    if isinstance(value, str) and value.startswith('L'):\n",
        "        try:\n",
        "            return int(value[1:])\n",
        "        except:\n",
        "            return 0\n",
        "    try:\n",
        "        return int(value)\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "# Preprocess recommended skills\n",
        "def preprocess_recommended_skills(df, columns):\n",
        "    for col in columns:\n",
        "        df[col + \"_dict\"] = df[col].fillna(\"\").str.split(\",\").apply(\n",
        "            lambda skills: {s.split(\"-\")[0].strip(): level_to_int(s.split(\"-\")[1].strip())\n",
        "                            for s in skills if \"-\" in s and len(s.split(\"-\")) == 2}\n",
        "        )\n",
        "    return df\n",
        "\n",
        "recommended_cols = ['skills_recommended_by_manager', 'skills_recommended_by_department', 'skills_selected_for_own']\n",
        "associates = preprocess_recommended_skills(associates, recommended_cols)\n",
        "\n",
        "# Optimized learning path function\n",
        "def create_learning_path_and_trainings(row):\n",
        "    associate_id = row[\"associate_id\"]\n",
        "    project_recommendations = []\n",
        "    project_skill_gaps = []\n",
        "    training_recommendations = []\n",
        "    training_skill_gaps = []\n",
        "    current_levels = []\n",
        "    recommended_levels = []\n",
        "    current_project_levels = []\n",
        "    recommended_project_levels = []\n",
        "\n",
        "    # Project-Based Learning Paths\n",
        "    assoc_skills = {skill: row[skill] for skill in skill_columns_assoc}\n",
        "    assoc_prefs = preferences[preferences[\"associate_id\"] == associate_id]\n",
        "    delivery_mode = assoc_prefs[\"preferred_format\"].iloc[0] if not assoc_prefs.empty else None\n",
        "    assoc_project_ids = [pid.strip() for pid in row[\"project_id\"].split(\",\")]\n",
        "    assoc_projects = projects[projects[\"project_id\"].isin(assoc_project_ids)]\n",
        "\n",
        "    if not assoc_projects.empty:\n",
        "        max_required_levels = {}\n",
        "        for skill in skill_columns_proj:\n",
        "            levels = assoc_projects[skill]\n",
        "            valid_levels = [skill_levels.get(level, 0) for level in levels if pd.notna(level) and level in skill_levels]\n",
        "            if valid_levels:\n",
        "                max_required_levels[skill] = {\n",
        "                    \"level\": inverse_skill_levels[max(valid_levels)],\n",
        "                    \"level_int\": max(valid_levels)\n",
        "                }\n",
        "\n",
        "        project_skills_levels = [\n",
        "            (req_skill, req_info[\"level\"])\n",
        "            for req_skill, req_info in max_required_levels.items()\n",
        "            if skill_levels.get(assoc_skills.get(req_skill, \"L0\"), 0) < req_info[\"level_int\"]\n",
        "        ]\n",
        "        if project_skills_levels:\n",
        "            batch_results = batch_recommend_courses(project_skills_levels, delivery_mode)\n",
        "            for (skill, level), course in batch_results.items():\n",
        "                current_level_int = skill_levels.get(assoc_skills.get(skill, \"L0\"), 0)\n",
        "                req_level_int = skill_levels.get(level, 0)\n",
        "                project_recommendations.append({\"skill\": skill, \"course\": course})\n",
        "                project_skill_gaps.append({\"skill\": skill, \"gap\": f\"L{current_level_int} → L{req_level_int}\"})\n",
        "                current_project_levels.append(f\"{skill} - L{current_level_int}\")\n",
        "                recommended_project_levels.append(f\"{skill} - L{req_level_int}\")\n",
        "\n",
        "    # Recommended Skills Training\n",
        "    all_recommended = {}\n",
        "    for col in [col + \"_dict\" for col in recommended_cols]:\n",
        "        rec_skills = row[col]\n",
        "        for skill, level in rec_skills.items():\n",
        "            all_recommended[skill] = max(level, all_recommended.get(skill, 0))\n",
        "\n",
        "    training_skills_levels = [\n",
        "        (skill, inverse_skill_levels[rec_level])\n",
        "        for skill, rec_level in sorted(all_recommended.items())\n",
        "        if rec_level > level_to_int(assoc_skills.get(skill, 0))\n",
        "    ]\n",
        "    if training_skills_levels:\n",
        "        batch_results = batch_recommend_courses(training_skills_levels, delivery_mode)\n",
        "        for (skill, level), course in batch_results.items():\n",
        "            current_level = level_to_int(assoc_skills.get(skill, 0))\n",
        "            rec_level = skill_levels.get(level, 0)\n",
        "            training_recommendations.append({\"skill\": skill, \"course\": course})\n",
        "            training_skill_gaps.append(f\"{skill} (L{current_level} → L{rec_level})\")\n",
        "            current_levels.append(f\"{skill} - L{current_level}\")\n",
        "            recommended_levels.append(f\"{skill} - L{rec_level}\")\n",
        "\n",
        "    # Format project outputs\n",
        "    project_skill_gaps_str = \", \".join(f\"{gap['skill']} ({gap['gap']})\" for gap in project_skill_gaps)\n",
        "    trainings_by_project = \", \".join(f\"{skill}: {course}\" for skill, course in\n",
        "                                     [(rec[\"skill\"], rec[\"course\"]) for rec in project_recommendations])\n",
        "\n",
        "    # Format training outputs\n",
        "    trainings_by_manager_dept_self = \", \".join(f\"{skill}: {course}\" for skill, course in\n",
        "                                               [(rec[\"skill\"], rec[\"course\"]) for rec in training_recommendations])\n",
        "\n",
        "    # Collaborative Training Recommendation\n",
        "    role = row[\"role\"]\n",
        "    same_role_associates = associates[associates[\"role\"] == role]\n",
        "    collaborative_gaps = []\n",
        "    for skill in skill_columns_assoc:\n",
        "        peer_levels = same_role_associates[skill].apply(level_to_int)\n",
        "        max_level = peer_levels.max()\n",
        "        if max_level > 0:\n",
        "            current_level = level_to_int(assoc_skills.get(skill, 0))\n",
        "            if current_level < max_level:\n",
        "                collaborative_gaps.append((skill, max_level, max_level - current_level))\n",
        "\n",
        "    collaborative_gaps.sort(key=lambda x: x[2], reverse=True)\n",
        "    top_gaps = collaborative_gaps[:3]\n",
        "    collab_skills_levels = [(skill, inverse_skill_levels[target_level]) for skill, target_level, _ in top_gaps]\n",
        "    collaborative_trainings_str = \"\"\n",
        "    if collab_skills_levels:\n",
        "        batch_results = batch_recommend_courses(collab_skills_levels, delivery_mode)\n",
        "        collaborative_trainings_str = \", \".join(f\"{skill}: {course}\" for (skill, _), course in batch_results.items())\n",
        "\n",
        "    return pd.Series({\n",
        "        \"project_recommendations\": project_recommendations,\n",
        "        \"project_skill_gaps\": project_skill_gaps_str,\n",
        "        \"training_recommendations\": training_recommendations,\n",
        "        \"skill_gaps_basedonrecommendation\": \", \".join(training_skill_gaps),\n",
        "        \"current_skill_levels\": \", \".join(current_levels),\n",
        "        \"recommended_skill_levels\": \", \".join(recommended_levels),\n",
        "        \"current_skill_levels_forproject\": \", \".join(current_project_levels),\n",
        "        \"recommended_skill_levels_forproject\": \", \".join(recommended_project_levels),\n",
        "        \"trainings_recommended_by_project\": trainings_by_project,\n",
        "        \"trainings_recommended_by_manager_department_self\": trainings_by_manager_dept_self,\n",
        "        \"collaborative_training_recommendation\": collaborative_trainings_str\n",
        "    })\n",
        "\n",
        "# Parallel execution\n",
        "def parallel_apply(df, func, num_processes=4):\n",
        "    with Pool(num_processes) as pool:\n",
        "        results = pool.map(func, [row for _, row in df.iterrows()])\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "print(\"Processing learning paths in parallel...\")\n",
        "results = parallel_apply(associates, create_learning_path_and_trainings)\n",
        "associates = pd.concat([associates, results], axis=1)\n",
        "\n",
        "# Define output columns\n",
        "output_columns = [\n",
        "    \"associate_id\", \"name\", \"role\", \"project_id\",\n",
        "    \"current_skill_levels\", \"recommended_skill_levels\",\n",
        "    \"current_skill_levels_forproject\", \"recommended_skill_levels_forproject\",\n",
        "    \"project_skill_gaps\", \"skill_gaps_basedonrecommendation\",\n",
        "    \"trainings_recommended_by_project\", \"trainings_recommended_by_manager_department_self\",\n",
        "    \"collaborative_training_recommendation\"\n",
        "]\n",
        "\n",
        "# Save results\n",
        "associates[output_columns].to_csv(\"combined_learning_pathways.csv\", index=False)\n",
        "\n",
        "print(\"✅ Combined project-based learning pathways and training assignments saved successfully!\")\n",
        "print(associates[output_columns].head(10))"
      ]
    }
  ]
}